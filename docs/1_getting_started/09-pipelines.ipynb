{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004f9a76-a752-4e84-9485-713124e8e0ea",
   "metadata": {},
   "source": [
    "# **Pipelines**\n",
    "\n",
    "## 1. Basics of GEOAnalytics Canada Pipelines\n",
    "\n",
    "Our Pipeline tool helps with developing and building portable, scalable machine learning (ML) workflows based on Docker containers.\n",
    "\n",
    "**The Pipelines platform consists of:**\n",
    "\n",
    "* A UI for managing and tracking pipelines and their execution\n",
    "* An engine for scheduling a pipeline’s execution\n",
    "* An SDK for defining, building, and deploying pipelines in Python\n",
    "\n",
    "A pipeline is a representation of a ML workflow containing the parameters required to run the pipeline and the inputs and outputs of each component. Each pipeline component is a self-contained code block, packaged as a Docker image.\n",
    "\n",
    "\n",
    "In this tutorial notebook, we will build our first Pipeline. First, run the following command to install all the packages and dependencies required for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca62465",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/couler-proj/couler\n",
      "  Cloning https://github.com/couler-proj/couler to /tmp/pip-req-build-tvbvuw6q\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/couler-proj/couler /tmp/pip-req-build-tvbvuw6q\n",
      "  Resolved https://github.com/couler-proj/couler to commit db7d4c32672315078ee023f0cc5af75164794b4d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyaml\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting kubernetes>=11.0.0\n",
      "  Downloading kubernetes-24.2.0-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting docker>=4.1.0\n",
      "  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting stringcase>=1.2.0\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting StringGenerator>=0.4.4\n",
      "  Downloading StringGenerator-0.4.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting packaging>=14.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.26.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.4.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=14.05.14\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.9.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.11.1-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.1/167.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools>=21.0.0\n",
      "  Downloading setuptools-65.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: couler, stringcase, StringGenerator\n",
      "  Building wheel for couler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for couler: filename=couler-0.1.1rc8-py3-none-any.whl size=68329 sha256=78227f80a33ddb7a092b65e5934b6f4e2778935a519d8abba104f5feb9396e72\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9r5xmudy/wheels/a1/1b/02/6632061ac58fa9919c8ec267c75a29f5dd49a516b5dabf87d2\n",
      "  Building wheel for stringcase (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3570 sha256=37c9cfd30c65f546adede3661ba7711acc381aadf807fbc70a0756d881194d38\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0a/0d/86/88baa0554de5fdccfc2b2ee060175eec0a85c12cdfd8fef566\n",
      "  Building wheel for StringGenerator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for StringGenerator: filename=StringGenerator-0.4.4-py3-none-any.whl size=12974 sha256=160e125f76b3a7bce1777055e33d7ec1f0f66ea37447359a7b40290b7514ae56\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/79/b5/a8/abafbb0ca59de3a710549a91b97acc548821aae5f54aa805d4\n",
      "Successfully built couler stringcase StringGenerator\n",
      "Installing collected packages: StringGenerator, stringcase, pyasn1, wrapt, websocket-client, urllib3, six, setuptools, rsa, pyyaml, pyparsing, pyasn1-modules, oauthlib, idna, charset-normalizer, certifi, cachetools, requests, python-dateutil, pyaml, packaging, google-auth, Deprecated, requests-oauthlib, docker, kubernetes, couler\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "earthdata 0.2.2 requires python-benedict<0.26,>=0.25, but you have python-benedict 0.24.3 which is incompatible.\n",
      "awscli 1.25.60 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.25.60 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 StringGenerator-0.4.4 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 couler-0.1.1rc8 docker-6.0.0 google-auth-2.11.1 idna-3.4 kubernetes-24.2.0 oauthlib-3.2.1 packaging-21.3 pyaml-21.10.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 python-dateutil-2.8.2 pyyaml-6.0 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 setuptools-65.4.0 six-1.16.0 stringcase-1.2.0 urllib3-1.26.12 websocket-client-1.4.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install git+https://github.com/couler-proj/couler --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ba386-e7ce-45f7-9d52-e5fcab35c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Building A Basic Pipeline\n",
    "\n",
    "After installing the required dependencies for this tutorial, \n",
    "we then need to import the necessary modules. \n",
    "Next, we define a job template that pacakges each step into its own Container. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4346907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couler.argo as couler\n",
    "from couler.argo_submitter import ArgoSubmitter\n",
    "from couler.core.templates.toleration import Toleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d08eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(name):\n",
    "    toleration = Toleration('ga.nodepool/type', 'NoSchedule', 'Exists')\n",
    "    couler.add_toleration(toleration) # pipeline/nodepool=pipe:NoSchedule\n",
    "    toleration2 = Toleration('kubernetes.azure.com/scalesetpriority', 'NoSchedule', 'Exists')\n",
    "    couler.add_toleration(toleration2)\n",
    "    couler.run_container(\n",
    "        image=\"docker/whalesay:latest\",\n",
    "        command=[\"cowsay\"],\n",
    "        args=[name],\n",
    "        step_name=name,\n",
    "        node_selector={'pipeline':'small'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb5727-5571-4ca7-a9d6-e5967c372b8d",
   "metadata": {},
   "source": [
    "The next two functions demonstrate the dependencies between each step that \n",
    "can be created. Further down, we will see a more complex example, however,\n",
    "declaring simple dependencies such as these to block subsequent steps from\n",
    "operating before a given step has finished running can prove to be a powerful\n",
    "tool when building complex products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aae3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     A\n",
    "#    / \\\n",
    "#   B   C\n",
    "#  /\n",
    "# D\n",
    "def linear():\n",
    "    couler.set_dependencies(lambda: job(name=\"A\"), dependencies=None)\n",
    "    couler.set_dependencies(lambda: job(name=\"B\"), dependencies=[\"A\"])\n",
    "    couler.set_dependencies(lambda: job(name=\"C\"), dependencies=[\"A\"])\n",
    "    couler.set_dependencies(lambda: job(name=\"D\"), dependencies=[\"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dce745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   A\n",
    "#  / \\\n",
    "# B   C\n",
    "#  \\ /\n",
    "#   D\n",
    "def diamond():\n",
    "    couler.dag( # DAG: Directed Acyclic Graph\n",
    "        [\n",
    "            [lambda: job(name=\"A\")],\n",
    "            [lambda: job(name=\"A\"), lambda: job(name=\"B\")],  # A -> B\n",
    "            [lambda: job(name=\"A\"), lambda: job(name=\"C\")],  # A -> C\n",
    "            [lambda: job(name=\"B\"), lambda: job(name=\"D\")],  # B -> D\n",
    "            [lambda: job(name=\"C\"), lambda: job(name=\"D\")],  # C -> D\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f693b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear()\n",
    "diamond()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc0b54-1b9c-40ec-acbb-9d50e234c51a",
   "metadata": {},
   "source": [
    "We then will submit our job to the `pipeline` namespace where jobs will be run.\n",
    "Other names will just result in errors. First, we declare which submitter we will\n",
    "be using - we will use the ArgoSubmitter as the backend is leveraging Argo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4d988de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Argo submitter namespace: pipeline\n",
      "INFO:root:Cannot find local k8s config. Trying in-cluster config.\n",
      "INFO:root:Initialized with in-cluster config.\n"
     ]
    }
   ],
   "source": [
    "submitter = ArgoSubmitter(namespace='pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c075eb-1f01-4aad-a418-884530665f16",
   "metadata": {},
   "source": [
    "Finally, we submit our Directed Acyclic Graph (DAG) that represents our \"pipeline\" we defined \n",
    "above to the Executor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d5dfeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Checking workflow name/generatedName runpy-\n",
      "INFO:root:Submitting workflow to Argo\n",
      "INFO:root:Workflow runpy-j8w5g has been submitted in \"pipeline\" namespace!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'argoproj.io/v1alpha1',\n",
       " 'kind': 'Workflow',\n",
       " 'metadata': {'creationTimestamp': '2022-09-27T02:44:08Z',\n",
       "  'generateName': 'runpy-',\n",
       "  'generation': 1,\n",
       "  'managedFields': [{'apiVersion': 'argoproj.io/v1alpha1',\n",
       "    'fieldsType': 'FieldsV1',\n",
       "    'fieldsV1': {'f:metadata': {'f:generateName': {}}, 'f:spec': {}},\n",
       "    'manager': 'OpenAPI-Generator',\n",
       "    'operation': 'Update',\n",
       "    'time': '2022-09-27T02:44:08Z'}],\n",
       "  'name': 'runpy-j8w5g',\n",
       "  'namespace': 'pipeline',\n",
       "  'resourceVersion': '42779483',\n",
       "  'uid': '6a864b5c-68d4-4bf0-8c2e-e4053f0b02e5'},\n",
       " 'spec': {'entrypoint': 'runpy',\n",
       "  'templates': [{'dag': {'tasks': [{'arguments': {'parameters': [{'name': 'para-A-0',\n",
       "          'value': 'A'}]},\n",
       "       'name': 'A',\n",
       "       'template': 'A'},\n",
       "      {'arguments': {'parameters': [{'name': 'para-B-0', 'value': 'B'}]},\n",
       "       'dependencies': ['A'],\n",
       "       'name': 'B',\n",
       "       'template': 'B'},\n",
       "      {'arguments': {'parameters': [{'name': 'para-C-0', 'value': 'C'}]},\n",
       "       'dependencies': ['A'],\n",
       "       'name': 'C',\n",
       "       'template': 'C'},\n",
       "      {'arguments': {'parameters': [{'name': 'para-D-0', 'value': 'D'}]},\n",
       "       'dependencies': ['B', 'C'],\n",
       "       'name': 'D',\n",
       "       'template': 'D'}]},\n",
       "    'name': 'runpy'},\n",
       "   {'container': {'args': ['{{inputs.parameters.para-A-0}}'],\n",
       "     'command': ['cowsay'],\n",
       "     'image': 'docker/whalesay:latest'},\n",
       "    'inputs': {'parameters': [{'name': 'para-A-0'}]},\n",
       "    'name': 'A',\n",
       "    'nodeSelector': {'pipeline': 'small'}},\n",
       "   {'container': {'args': ['{{inputs.parameters.para-B-0}}'],\n",
       "     'command': ['cowsay'],\n",
       "     'image': 'docker/whalesay:latest'},\n",
       "    'inputs': {'parameters': [{'name': 'para-B-0'}]},\n",
       "    'name': 'B',\n",
       "    'nodeSelector': {'pipeline': 'small'}},\n",
       "   {'container': {'args': ['{{inputs.parameters.para-C-0}}'],\n",
       "     'command': ['cowsay'],\n",
       "     'image': 'docker/whalesay:latest'},\n",
       "    'inputs': {'parameters': [{'name': 'para-C-0'}]},\n",
       "    'name': 'C',\n",
       "    'nodeSelector': {'pipeline': 'small'}},\n",
       "   {'container': {'args': ['{{inputs.parameters.para-D-0}}'],\n",
       "     'command': ['cowsay'],\n",
       "     'image': 'docker/whalesay:latest'},\n",
       "    'inputs': {'parameters': [{'name': 'para-D-0'}]},\n",
       "    'name': 'D',\n",
       "    'nodeSelector': {'pipeline': 'small'}}],\n",
       "  'tolerations': [{'effect': 'NoSchedule',\n",
       "    'key': 'ga.nodepool/type',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'}]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment = couler.run(submitter=submitter)\n",
    "deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fef5e",
   "metadata": {},
   "source": [
    "The following screenshot shows the successful run that the above JSON pipeline object represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3b125",
   "metadata": {},
   "source": [
    "![pipeline DAG](../images/getting_started_images/09_pipeline-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce277570",
   "metadata": {},
   "source": [
    "And finally, the output of the above pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5de5e",
   "metadata": {},
   "source": [
    "![whalesayAB](../images/getting_started_images/09_whalesayAB.png)![whalesayCD](../images/getting_started_images/09_whalesayCD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d481c95-8b02-4dec-bbce-3a23ba712b9a",
   "metadata": {},
   "source": [
    "## X. Building A More Complex Pipeline\n",
    "\n",
    "In this example, we stub out a pseudo-pipeline for a Failover Mechanism while processing Sen2Cor. \n",
    "\n",
    "The idea is to begin with the most recent version of Sen2Cor and then if an error occurs while\n",
    "processing the L1C input then it will failover to the next release of Sen2Cor. \n",
    "If the process fails over on all conditions, then an error job is thrown to perform \n",
    "what would be any cleanup and notification of fail on a certain input. \n",
    "\n",
    "This pipeline can be adapted into many other uses. \n",
    "\n",
    "First, after importing our libraries, we build a template job function that can take in `callable` objects to be inserted in to a Python3.6 image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d7f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import couler.argo as couler\n",
    "from couler.argo_submitter import ArgoSubmitter\n",
    "from couler.core.templates.toleration import Toleration\n",
    "from couler.core.templates.volume_claim import VolumeClaimTemplate\n",
    "from couler.core.constants import WFStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1da06e-af05-4522-b168-12c32ff18973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(name: str, source: callable):\n",
    "    toleration = Toleration('ga.nodepool/type', 'NoSchedule', 'Exists')\n",
    "    couler.add_toleration(toleration) # pipeline/nodepool=pipe:NoSchedule\n",
    "    toleration2 = Toleration('kubernetes.azure.com/scalesetpriority', 'NoSchedule', 'Exists')\n",
    "    couler.add_toleration(toleration2)\n",
    "    return couler.run_script(\n",
    "        image=\"python:alpine3.6\",\n",
    "        source=source,\n",
    "        step_name=name,\n",
    "        node_selector={'pipeline':'small'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be09a24",
   "metadata": {},
   "source": [
    "Next, we define our steps that represent success or failure of running the Sen2Cor binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3452ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_files():\n",
    "    return ['ras1','ras2','ras3','ras4']\n",
    "\n",
    "def preprocess():\n",
    "    print(f'preprocess')\n",
    "    \n",
    "def sen2cor290():  \n",
    "    import random\n",
    "    task = ['success', 'fail']\n",
    "    res = random.randint(0, 1)\n",
    "    res = task[res]\n",
    "    print(f'{res}')\n",
    "    if res == 'fail':\n",
    "        sys.exit(2)\n",
    "\n",
    "def sen2cor280():\n",
    "    import random\n",
    "    task = ['success', 'fail']\n",
    "    res = random.randint(0, 1)\n",
    "    res = task[res]\n",
    "    print(f'{res}')\n",
    "    if res == 'fail':\n",
    "        sys.exit(2)\n",
    "    \n",
    "def sen2cor255():\n",
    "    import random\n",
    "    task = ['success', 'fail']\n",
    "    res = random.randint(0, 1)\n",
    "    res = task[res]\n",
    "    print(f'{res}')\n",
    "    if res == 'fail':\n",
    "        sys.exit(2)\n",
    "\n",
    "def fin():\n",
    "    print('fin')\n",
    "\n",
    "def err():\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba254f3",
   "metadata": {},
   "source": [
    "Once decalared, we wrap our functions inside of a submittable job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e776b7f8-b2fe-4722-a7cc-db3969fdbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_job():\n",
    "    return job(name='preprocess', source=preprocess)\n",
    "\n",
    "def sen2cor290_job():\n",
    "    return job(name='sen2cor290', source=sen2cor290)\n",
    "\n",
    "def sen2cor280_job():\n",
    "    return job(name='sen2cor280', source=sen2cor280)\n",
    "\n",
    "def sen2cor255_job():\n",
    "    return job(name='sen2cor255', source=sen2cor255)\n",
    "\n",
    "def fin_job():\n",
    "    return job(name='fin', source=fin)\n",
    "\n",
    "def err_job():\n",
    "    return job(name='err', source=err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d65c0",
   "metadata": {},
   "source": [
    "We now need to build our DAG\n",
    "\n",
    "First we gather our files, which is generally a list and then any necessary preprocessing steps. \n",
    "Once ready, the input is passed into our first Step: \"Sen2Cor version 2.9.0\". \n",
    "Using Boolean logic, we can determine how the failovers are managed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f0df77-e1da-4eca-bfbb-1d61db664c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dag(pth):\n",
    "\n",
    "    couler.set_dependencies(\n",
    "        preprocess_job, \n",
    "        dependencies=None\n",
    "    )\n",
    "    \n",
    "    couler.set_dependencies(\n",
    "        sen2cor290_job,\n",
    "        dependencies='preprocess.Succeeded'\n",
    "    )\n",
    "\n",
    "    couler.set_dependencies(\n",
    "        sen2cor280_job,\n",
    "        dependencies='sen2cor290.Failed'\n",
    "    )\n",
    "\n",
    "    couler.set_dependencies(\n",
    "        sen2cor255_job,\n",
    "        dependencies='sen2cor280.Failed'\n",
    "    )\n",
    "    \n",
    "    couler.set_dependencies(\n",
    "        err_job,\n",
    "        dependencies='sen2cor280.Failed && sen2cor290.Failed && sen2cor255.Failed'\n",
    "    )\n",
    "    \n",
    "    couler.set_dependencies(\n",
    "        fin_job,\n",
    "        dependencies='sen2cor290.Succeeded || sen2cor280.Succeeded || sen2cor255.Succeeded'\n",
    "    )\n",
    "    \n",
    "run_dag('pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23388c",
   "metadata": {},
   "source": [
    "Finally, we submit our job to the Executor! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c917d2-6e3e-475c-99b9-c42294fb7102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Argo submitter namespace: pipeline\n",
      "INFO:root:Cannot find local k8s config. Trying in-cluster config.\n",
      "INFO:root:Initialized with in-cluster config.\n"
     ]
    }
   ],
   "source": [
    "submitter = ArgoSubmitter(namespace='pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2d6fe2-b83e-4793-a7c7-15b137fdfdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Checking workflow name/generatedName runpy-\n",
      "INFO:root:Submitting workflow to Argo\n",
      "INFO:root:Workflow runpy-knlcd has been submitted in \"pipeline\" namespace!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'argoproj.io/v1alpha1',\n",
       " 'kind': 'Workflow',\n",
       " 'metadata': {'creationTimestamp': '2022-09-27T02:37:01Z',\n",
       "  'generateName': 'runpy-',\n",
       "  'generation': 1,\n",
       "  'managedFields': [{'apiVersion': 'argoproj.io/v1alpha1',\n",
       "    'fieldsType': 'FieldsV1',\n",
       "    'fieldsV1': {'f:metadata': {'f:generateName': {}}, 'f:spec': {}},\n",
       "    'manager': 'OpenAPI-Generator',\n",
       "    'operation': 'Update',\n",
       "    'time': '2022-09-27T02:37:01Z'}],\n",
       "  'name': 'runpy-knlcd',\n",
       "  'namespace': 'pipeline',\n",
       "  'resourceVersion': '42775569',\n",
       "  'uid': 'd3fef132-6be1-47f6-bd21-0c8ef710b7d0'},\n",
       " 'spec': {'entrypoint': 'runpy',\n",
       "  'templates': [{'dag': {'tasks': [{'name': 'preprocess',\n",
       "       'template': 'preprocess'},\n",
       "      {'depends': 'preprocess.Succeeded',\n",
       "       'name': 'sen2cor290',\n",
       "       'template': 'sen2cor290'},\n",
       "      {'depends': 'sen2cor290.Failed',\n",
       "       'name': 'sen2cor280',\n",
       "       'template': 'sen2cor280'},\n",
       "      {'depends': 'sen2cor280.Failed',\n",
       "       'name': 'sen2cor255',\n",
       "       'template': 'sen2cor255'},\n",
       "      {'depends': 'sen2cor280.Failed && sen2cor290.Failed && sen2cor255.Failed',\n",
       "       'name': 'err',\n",
       "       'template': 'err'},\n",
       "      {'depends': 'sen2cor290.Succeeded || sen2cor280.Succeeded || sen2cor255.Succeeded',\n",
       "       'name': 'fin',\n",
       "       'template': 'fin'}]},\n",
       "    'name': 'runpy'},\n",
       "   {'name': 'preprocess',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\nprint(f'preprocess')\\n\"}},\n",
       "   {'name': 'sen2cor290',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\ntask = ['success', 'fail']\\nres = random.randint(0, 1)\\nres = task[res]\\nprint(f'{res}')\\nif res == 'fail':\\n    sys.exit(2)\\n\"}},\n",
       "   {'name': 'sen2cor280',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\ntask = ['success', 'fail']\\nres = random.randint(0, 1)\\nres = task[res]\\nprint(f'{res}')\\nif res == 'fail':\\n    sys.exit(2)\\n\"}},\n",
       "   {'name': 'sen2cor255',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\ntask = ['success', 'fail']\\nres = random.randint(0, 1)\\nres = task[res]\\nprint(f'{res}')\\nif res == 'fail':\\n    sys.exit(2)\\n\"}},\n",
       "   {'name': 'err',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\nprint('error')\\n\"}},\n",
       "   {'name': 'fin',\n",
       "    'nodeSelector': {'pipeline': 'small'},\n",
       "    'script': {'command': ['python'],\n",
       "     'image': 'python:alpine3.6',\n",
       "     'source': \"\\nprint('fin')\\n\"}}],\n",
       "  'tolerations': [{'effect': 'NoSchedule',\n",
       "    'key': 'ga.nodepool/type',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule', 'key': 'ga.nodepool/type', 'operator': 'Exists'},\n",
       "   {'effect': 'NoSchedule',\n",
       "    'key': 'kubernetes.azure.com/scalesetpriority',\n",
       "    'operator': 'Exists'}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couler.run(submitter=submitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97919bd5-e16a-4337-a0f9-21f3b7081943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
